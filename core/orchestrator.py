"""
CAM Core Orchestrator

The brain of CAM. Runs the main OBSERVE → THINK → ACT → ITERATE loop
that drives all autonomous behavior.

Right now this is the skeleton — placeholders where the model router,
memory system, and tool framework will plug in later. But the loop
structure and task flow are real and ready to build on.

Usage:
    from core.orchestrator import Orchestrator

    orch = Orchestrator()
    orch.add_task("research Harley-Davidson M-8 oil pump recall")
    await orch.run()
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any


# ---------------------------------------------------------------------------
# Logging — every action gets a record (CLAUDE.md coding conventions)
# ---------------------------------------------------------------------------

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger("cam.orchestrator")


# ---------------------------------------------------------------------------
# Task model
# ---------------------------------------------------------------------------

class TaskStatus(Enum):
    """Lifecycle states for a task in the queue."""
    PENDING = "pending"        # Waiting to be picked up
    IN_PROGRESS = "in_progress"  # Currently being worked on
    COMPLETED = "completed"    # Finished successfully
    FAILED = "failed"          # Finished with an error


@dataclass
class Task:
    """A unit of work for CAM to process.

    Tasks come from various sources: CLI commands, dashboard messages,
    scheduled jobs, or follow-up tasks generated by the ITERATE phase.

    Attributes:
        task_id:     Unique identifier (auto-incremented)
        description: What needs to be done, in plain English
        source:      Where the task came from (e.g., "cli", "dashboard", "schedule")
        status:      Current lifecycle state
        created_at:  When the task was added to the queue
        result:      Output from the ACT phase (None until completed)
    """
    task_id: int
    description: str
    source: str = "internal"
    status: TaskStatus = TaskStatus.PENDING
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    result: Any = None


# ---------------------------------------------------------------------------
# Orchestrator
# ---------------------------------------------------------------------------

class Orchestrator:
    """Main agent loop for CAM.

    The orchestrator runs a continuous loop with four phases:

        OBSERVE  — Check for new tasks from the queue
        THINK    — Analyze the task, plan an approach
        ACT      — Execute the plan (tools, model calls, sub-agents)
        ITERATE  — Log results, update memory, check for follow-ups

    Right now THINK and ACT are placeholders. As we build out the model
    router, memory system, and tool framework, they'll gain real logic.

    The queue is in-memory for now. Phase 1 gets this loop running;
    persistent task storage (JSON/SQLite) comes with the working memory
    module in core/memory/working.py.
    """

    def __init__(self):
        # Task queue — simple list, processed in order (FIFO)
        self._queue: list[Task] = []

        # Counter for generating unique task IDs
        self._next_id: int = 1

        # Flag to stop the loop gracefully (kill switch, shutdown, etc.)
        self._running: bool = False

        # How long to wait between loop iterations when idle (seconds).
        # Keeps CPU usage near zero when there's nothing to do.
        self._poll_interval: float = 1.0

        logger.info("Orchestrator initialized")

    # -------------------------------------------------------------------
    # Task management
    # -------------------------------------------------------------------

    def add_task(self, description: str, source: str = "internal") -> Task:
        """Add a new task to the queue.

        This is how work gets into CAM — the CLI, dashboard, scheduled
        jobs, and sub-agents all feed tasks through here.

        Args:
            description: What needs to be done, in plain English.
            source:      Where this task came from (for logging/audit).

        Returns:
            The created Task object.
        """
        task = Task(
            task_id=self._next_id,
            description=description,
            source=source,
        )
        self._next_id += 1
        self._queue.append(task)
        logger.info(
            "Task #%d added (source=%s): %s",
            task.task_id, task.source, task.description,
        )
        return task

    def get_pending_tasks(self) -> list[Task]:
        """Return all tasks that haven't been picked up yet."""
        return [t for t in self._queue if t.status == TaskStatus.PENDING]

    # -------------------------------------------------------------------
    # The four phases
    # -------------------------------------------------------------------

    async def observe(self) -> Task | None:
        """OBSERVE — Check for new work.

        Scans the task queue for the next pending task. In the future
        this will also check:
        - CLI input buffer
        - Dashboard WebSocket commands
        - Scheduled task timers
        - Mobile app messages
        - Voice call transcriptions

        Returns:
            The next Task to work on, or None if the queue is empty.
        """
        pending = self.get_pending_tasks()
        if not pending:
            return None

        # Pick the oldest pending task (FIFO)
        task = pending[0]
        task.status = TaskStatus.IN_PROGRESS
        logger.info(
            "[OBSERVE] Picked up task #%d: %s",
            task.task_id, task.description,
        )
        return task

    async def think(self, task: Task) -> dict:
        """THINK — Analyze the task and plan an approach.

        This is where the model router will be called to:
        - Classify the task complexity (simple/routine/complex/nuanced)
        - Retrieve relevant memory (long-term knowledge, past episodes)
        - Choose the right model for the job
        - Break complex tasks into sub-steps
        - Determine which tools or sub-agents are needed

        For now: logs the task and returns a placeholder plan.

        Args:
            task: The task to analyze.

        Returns:
            A plan dictionary describing what to do.
        """
        logger.info(
            "[THINK] Analyzing task #%d: %s",
            task.task_id, task.description,
        )

        # Placeholder — will be replaced by model router + memory lookup
        plan = {
            "task_id": task.task_id,
            "description": task.description,
            "complexity": "simple",       # Future: model router classifies this
            "model": "placeholder",       # Future: route to Ollama/Kimi/Claude
            "tools_needed": [],           # Future: identify required tools
            "sub_tasks": [],              # Future: break into steps
        }

        logger.info(
            "[THINK] Plan for task #%d: complexity=%s",
            task.task_id, plan["complexity"],
        )
        return plan

    async def act(self, task: Task, plan: dict) -> str:
        """ACT — Execute the plan.

        This is where tools get called, sub-agents get dispatched,
        and model responses get generated. The security framework
        will classify every action before execution (safe/logged/
        gated/blocked per the Constitution).

        For now: returns a mock result string.

        Args:
            task: The task being executed.
            plan: The plan from the THINK phase.

        Returns:
            A result string describing what was done.
        """
        logger.info(
            "[ACT] Executing task #%d: %s",
            task.task_id, task.description,
        )

        # Placeholder — will be replaced by tool execution + model calls
        result = f"Completed: {task.description}"

        logger.info(
            "[ACT] Task #%d result: %s",
            task.task_id, result,
        )
        return result

    async def iterate(self, task: Task, result: str):
        """ITERATE — Wrap up and learn.

        After a task is done, this phase:
        - Updates the task status and stores the result
        - Logs the completed action to the audit trail
        - Updates memory (episodic log, working state)
        - Checks if the result spawns follow-up tasks

        For now: marks the task complete and logs it.

        Args:
            task:   The completed task.
            result: The output from the ACT phase.
        """
        task.status = TaskStatus.COMPLETED
        task.result = result

        logger.info(
            "[ITERATE] Task #%d completed: %s",
            task.task_id, result,
        )

        # Future: save to episodic memory
        # Future: update working memory state
        # Future: check for follow-up tasks and add them to the queue

    # -------------------------------------------------------------------
    # Main loop
    # -------------------------------------------------------------------

    async def run(self):
        """Run the orchestrator loop.

        Continuously cycles through OBSERVE → THINK → ACT → ITERATE
        until stopped. When there's nothing to do, sleeps briefly to
        avoid burning CPU.

        Stop the loop by calling stop() or setting _running = False.
        """
        self._running = True
        logger.info("Orchestrator loop started")

        try:
            while self._running:
                # OBSERVE — look for work
                task = await self.observe()

                if task is None:
                    # Nothing to do — sleep and check again
                    await asyncio.sleep(self._poll_interval)
                    continue

                try:
                    # THINK — plan the approach
                    plan = await self.think(task)

                    # ACT — execute the plan
                    result = await self.act(task, plan)

                    # ITERATE — wrap up, log, learn
                    await self.iterate(task, result)

                except Exception as e:
                    # Task failed — log it, mark it, keep the loop running.
                    # Constitution failure hierarchy: stop action, secure,
                    # notify George, log, wait for direction.
                    task.status = TaskStatus.FAILED
                    task.result = str(e)
                    logger.error(
                        "Task #%d failed: %s", task.task_id, e, exc_info=True,
                    )

        except asyncio.CancelledError:
            logger.info("Orchestrator loop cancelled")
        finally:
            self._running = False
            logger.info("Orchestrator loop stopped")

    def stop(self):
        """Signal the orchestrator to stop after the current iteration.

        This is the graceful shutdown path — the loop finishes its
        current task (if any) and then exits. Used by the kill switch
        and clean shutdown handlers.
        """
        logger.info("Orchestrator stop requested")
        self._running = False

    # -------------------------------------------------------------------
    # Status
    # -------------------------------------------------------------------

    @property
    def is_running(self) -> bool:
        """Whether the orchestrator loop is currently active."""
        return self._running

    @property
    def queue_size(self) -> int:
        """Number of pending tasks in the queue."""
        return len(self.get_pending_tasks())

    def get_status(self) -> dict:
        """Return a snapshot of the orchestrator's current state.

        Useful for the dashboard status panel.
        """
        return {
            "running": self._running,
            "pending_tasks": self.queue_size,
            "total_tasks": len(self._queue),
            "completed": len([t for t in self._queue if t.status == TaskStatus.COMPLETED]),
            "failed": len([t for t in self._queue if t.status == TaskStatus.FAILED]),
        }


# ---------------------------------------------------------------------------
# Direct execution — quick test
# ---------------------------------------------------------------------------

async def _test():
    """Quick smoke test: add a task and run the loop."""
    orch = Orchestrator()

    # Add a couple of test tasks
    orch.add_task("research Harley-Davidson M-8 oil pump recall", source="cli")
    orch.add_task("draft YouTube script for barn find CB750", source="dashboard")

    # Run the loop — it will process both tasks and then idle
    # We'll stop it after a short delay
    async def stop_after_delay():
        await asyncio.sleep(3)
        orch.stop()

    await asyncio.gather(orch.run(), stop_after_delay())

    # Print final status
    status = orch.get_status()
    print(f"\nFinal status: {status}")
    for task in orch._queue:
        print(f"  Task #{task.task_id} [{task.status.value}]: {task.result}")


if __name__ == "__main__":
    asyncio.run(_test())
